##  如何解释【卷积神经网络】

####    目标

介绍CNNs的基础结构和训练方法。

####    概况
概述神经网络(neual networks)是人工智能研究领域的一部分，当前最流行的神经网络是深度卷积神经网络(deep convolutional neural networks, CNNs)，虽然卷积网络也存在浅层结构，但是因为准确度和表现力等原因很少使用。目前提到CNNs和卷积神经网络，学术界和工业界不再进行特意区分，一般都指深层结构的卷积神经网络，层数从”几层“到”几十上百“不定。CNNs目前在很多很多研究领域取得了巨大的成功，例如: 语音识别，图像识别，图像分割，自然语言处理等。虽然这些领域中解决的问题并不相同，但是这些应用方法都可以被归纳为:
>CNNs可以自动从(通常是大规模)数据中学习特征，并把结果向同类型未知数据泛化。

####    背景
半个世纪以前，图像识别就已经是一个火热的研究课题。1950年中-1960年初，感知机吸引了机器学习学者的广泛关注。这是因为当时数学证明表明，如果输入数据线性可分，感知机可以在有限迭代次数内收敛[1]。感知机的解是超平面参数集，这个超平面可以用作数据分类。然而，感知机却在实际应用中遇到了很大困难，因为    1)多层感知机暂时没有有效训练方法，导致层数无法加深；    2)由于采用线性激活函数，导致无法处理线性不可分问题，比如“与或”。这些问题随着后向传播(back propagation，BP)算法和非线性激活函数的提出得到解决。1989年，BP算法被首次用于CNN中处理2-D信号(图像)。2012年，ImageNet挑战赛中CNN证明了它的实力，从此在图像识别和其他应用中被广泛采纳。通过机器进行模式识别 ，通常可以被认为有四个阶段:
+ 数据获取: 比如数字化图像
+ 预处理: 比如图像去噪和图像几何修正
+ 特征提取：寻找一些计算机识别的属性，这些属性用以描述当前图像与其它图像的不同之处
+ 数据分类：把输入图像划分给某一特定类别CNN是目前图像领域特征提取最好的方式，也因此大幅度提升了数据分类精度，我将在下文详细解释。

####    网络结构
基础的CNN由 **卷积**(convolution), **激活**(activation), and **池化**(pooling)三种结构组成。CNN输出的结果是每幅图像的特定特征空间。*当处理图像分类任务时，我们会把CNN输出的特征空间作为全连接层或全连接神经网络(fully connected neural network, FCN)的输入，用全连接层来完成从输入图像到标签集的映射，即分类。*当然，整个过程最重要的工作就是如何通过训练数据迭代调整网络权重，也就是后向传播算法。目前主流的卷积神经网络(CNNs)，比如VGG, ResNet都是由简单的CNN调整，组合而来。

这些加粗名词将会在下文详细解释。

####    CNN
![图1 某个stage内CNN工作原理](https://pic3.zhimg.com/80/v2-d7914b4b7a8d44b856e8968e6b426fca_hd.jpg)

图1显示的是CNN的基础结构，现在大型深层的卷积神经网络(CNNs, 请注意这里是复数)通常由多个上述结构前后连接、层内调整组成，根据功能不同，我们称这些前后连接的结构处于不同**阶段**(stage)。虽然在主流CNNs中，不同stage里CNN会有不同的单元和结构，比如**卷积核** (kernel)大小可能不同，**激活函数**(activition function) 可能不同，pooling操作可能不存在，但是图1的CNN结构应当能够包含所有的情况。

我们跟随图1来解释，一个stage中的一个CNN，通常会由三种映射空间组成(Maps Volume, 这里不确定是不是应该翻译为映射空间，或许映射体积会更准确),
+ 输入映射空间(input maps volume）
+ 特征映射空间(feature maps volume）
+ 池化映射空间(pooled maps volume)

例如图中，输入的是彩色RGB图像，那么输入的maps volume由红，黄，蓝三通道/三种map构成。我们之所以用input map volume这个词来形容，是因为对于多通道图像输入图像实际上是由高度，宽度，深度三种信息构成,可以被形象理解为一种"体积"。这里的“深度”，在RGB中就是3，红，黄，蓝三种颜色构成的图像，在灰度图像中，就是1。

####    卷积
CNN中最基础的操作是**卷积convolution**，再精确一点，基础CNN所用的卷积是一种2-D卷积。也就是说，kernel只能在x,y上滑动位移，不能进行深度 (跨通道) 位移。这可以根据图1来理解，对于图中的RGB图像，采用了三个独立的2-D kernel，如黄色部分所示，所以这个kernel的维度是 ![X*Y*Chanenels](https://www.zhihu.com/equation?tex=X%5Ctimes+Y+%5Ctimes+3) 。在基础CNN的不同stage中，kernel的深度都应当一致，等于输入图像的通道数。

卷积需要输入两个参数，实质是二维空间滤波，滤波的性质与kernel选择有关，CNN的卷积是在一个2-D kernel 和输入的 2-D input map 之间，RGB中各图像通道分别完成。

我们假设单一通道输入图像的空间坐标为![](https://www.zhihu.com/equation?tex=%28x%2Cy%29)  ，卷积核大小是![](https://www.zhihu.com/equation?tex=p+%5Ctimes+q)  ，kernel权重为![](https://www.zhihu.com/equation?tex=w)  ,图像亮度值是![](https://www.zhihu.com/equation?tex=v)  ，**卷积过程就是kernel 单元权重与输入图像对应元素亮度乘积之和**，可以表示为![](https://www.zhihu.com/equation?tex=conv_%7Bx%2Cy%7D+%3D+%5Csum_i%5E%7Bp%2Aq%7Dw_iv_i)

我们可以用一个例子来说明。
![](https://pic3.zhimg.com/80/v2-71c1c98813face244f00dc62a6a18cb2_hd.jpg)

如上图所示，这时候输出的单一元素是
![](https://www.zhihu.com/equation?tex=conv_%7Bx%2Cy%7D+%3D+105%2A0+%2B+102%2A%28-1%29%2B100%2A0%2B103%2A%28-1%29%2B99%2A5+%2B103%2A%28-1%29%2B101%2A0%2B98%2A%28-1%29%2B104%2A0%5C%5C+%3D89)

并将kernel随(x,y)平移扫描，可以得到输出空间，这时假设输入图像大小是![](https://www.zhihu.com/equation?tex=512+%5Ctimes+512) ，卷积核是 ![](https://www.zhihu.com/equation?tex=3+%5Ctimes+3) ，在不考虑零填充（zero padding）的情况，输出是 ![](https://www.zhihu.com/equation?tex=%EF%BC%88510%2Fn%2C510%2Fn%EF%BC%89)
注意卷积层的kernel可能不止一个，扫描步长，方向也有不同，这些进阶方式可以归纳一下:
+ 可以采用多个卷积核，设为n 同时扫描，得到的feature map会增加n个维度，通常认为是多抓取n个特征。
+ 可以采取不同扫描步长，比如上例子中采用步长为n, 输出是 ![](https://www.zhihu.com/equation?tex=%28512-3%2B1%29%3D510+%5Ctimes+510.)
+ padding，上例里，卷积过后图像维度是缩减的，可以在图像周围填充0来保证feature map与原始图像大小不变
+ 深度升降，例如采用增加一个1*1 kernel来增加深度，相当于复制一层当前通道作为feature map
+ 跨层传递feature map,不再局限于输入即输出, 例如ResNet跨层传递特征，Faster RCNN 的POI pooling

####    激活

卷积之后，通常会加入偏置(bias), 并引入非线性激活函数(activation function)，这里定义bias为b，activation function 是 ![](https://www.zhihu.com/equation?tex=h%28%29) ，经过激活函数后，得到的结果是,

![](https://www.zhihu.com/equation?tex=z_%7Bx%2Cy%7D%3Dh%28%5Csum_i%5E%7Bp%2Aq%7Dw_i+v_i%2Bb%29)

这里请注意，bias不与元素位置相关，只与层有关。主流的activation function 有,
线性整流单元(ReLU): ![](https://www.zhihu.com/equation?tex=h%28z%29+%3D+max+%280%2Cz%29)

<img src="https://pic3.zhimg.com/v2-25f3ae7165461dde90e6ece23f4988be_b.jpg" data-caption="" data-size="normal" data-rawwidth="120" data-rawheight="60" class="content_image" width="120"/>

Sigmoid函数： ![](https://www.zhihu.com/equation?tex=h%28z%29%3D1%2F%281%2Be%5E%7B-z%7D%29)

<img src="https://pic3.zhimg.com/v2-5ed550518bb5724f4b123cc62864b0ba_b.jpg" data-caption="" data-size="normal" data-rawwidth="120" data-rawheight="60" class="content_image" width="120"/>

anh函数: ![](https://www.zhihu.com/equation?tex=h%28z%29%3Dtanh%28z%29)

<img src="https://pic2.zhimg.com/v2-159df75e7ddb6f68e18520cac1780621_b.jpg" data-caption="" data-size="normal" data-rawwidth="120" data-rawheight="60" class="content_image" width="120"/>

根据实际参数大小等性质调整。

图1中feature maps volume的每个元素就是由 ![](https://www.zhihu.com/equation?tex=z_%7Bx%2Cy%7D) 。我们可以回到图1的上半部分，这里的feature map是可以可视化的。

![](https://pic3.zhimg.com/80/v2-d7914b4b7a8d44b856e8968e6b426fca_hd.jpg) 

例如采用277*277的RGB图像， 采用96个11*11*3的kernels同时扫描，很容易得到输出的feature maps是96个267*267的二维 feature map, 267*267是单个图像feature map的x,y轴大小，96是卷积核个数，原本的3通道在积分的时候会被作为一个元素加起来。 如上图，这些feature map可视化之后，可以看到4 和35表示边缘特征，23是模糊化的输入，10和16在强调灰度变化，39强调眼睛，45强调红色通道的表现。

####    池化

池化(pooling），是一种降采样操作(subsampling)，主要目标是降低feature maps的特征空间，或者可以认为是降低feature maps的分辨率。因为feature map参数太多，而图像细节不利于高层特征的抽取。

![图2 池化操作](https://pic2.zhimg.com/80/v2-290efadf80ec9c8dd2af256f8aa14e49_hd.jpg) 


目前主要的pooling操作有:
+ 最大值池化 Max pooling：如上图所示，2 * 2的max pooling就是取4个像素点中最大值保留
+ 平均值池化 Average pooling: 如上图所示, 2 * 2的average pooling就是取4个像素点中平均值值保留L2池化 
+ L2 pooling: 即取均方值保留

Pooling操作会降低参数，降低feature maps的分辨率，但是这种暴力降低在计算力足够的情况下是不是必须的，并不确定。目前一些大的CNNs网络只是偶尔使用pooling.以上是一个CNN stage的基本结构，需要强调的是，这个结构是可变的，目前大部分网络都是根据基本结构堆叠调整参数，或跳层连接而成。CNN的输出是feature maps，它不仅仅可以被输入全连接网络来分类，也可以接入另外一个“镜像”的CNN，如果输入图像维度与这个新的CNN输出feature maps特征维度相同，即这个新接入的CNN在做上采样, upsampling， 得到的图像可以认为是在做像素级的标注，图像分割[2]。

####    全连接网络

出现在CNN中的全连接网络(fully connected network)主要目的是为了分类, 这里称它为network的原因是，目前CNNs多数会采用多层全连接层，这样的结构可以被认为是网络。如果只有一层，下边的叙述同样适用。它的结构可能如下图所示:

![全连接层结构](https://pic3.zhimg.com/80/v2-b55f96358b1f1bc8f6a4e94dd1367952_hd.jpg) 

不同于CNN的滑动卷积，全连接网络每一层的所有单元与上一层完全连接。通常，除了输入层和输出层的其他层，都被认为是隐含层。如图2所示，对于第 *l* 层的第 *i* 个神经元，它的输出计算方式是

![](https://www.zhihu.com/equation?tex=z_i%28l%29%3D%5Csum_%7Bj%3Di%7D%5E%7Bn_%7Bl-1%7D%7Dw_%7Bij%7D%28l%29a_j%28l-1%29%2Bb_i%28l%29%2C) 

考虑activation function之后,对于第 *l* 层的第 *i* 个神经元，它的输出

![](https://www.zhihu.com/equation?tex=a_i%7B%28l%29%7D%3Dh%28z_i%28l%29%29.) 

计算这一层中的所有神经元之后, 作为下一层的输入。

全连接网络和CNN的数学表达结构其实很相似，只是不存在关于图像空间上的滑动卷积。

####    目标函数与训练方法

CNN网络的训练误差需要通过一个目标函数来衡量，目前比较流行的目标函数是均方误差(Mean Square Error)和K-L散度（K-L divergence)，对于输出层的误差公式很容易判断:

+ MSE: 
![](https://www.zhihu.com/equation?tex=E+%3D+%5Cfrac%7B1%7D%7B2%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_L%7D%28r_j-a_j%28L%29%29%5E2%2C) 

+ K-L divergence: 
![](https://www.zhihu.com/equation?tex=E+%3D+-+%5Cfrac%7B1%7D%7Bn_L%7D%5Csum_%7Bj%3D1%7D%5E%7Bn_L%7D%5Br_j%5Cln+a_j%28L%29%2B%281-r_j%29%5Cln%281-a_j%28L%29%29%5D) 

通过后向传播进行权重更新
![](https://pic3.zhimg.com/80/v2-fae05dd064ba83bd5bb18c6ca81b4aca_hd.jpg) 